{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/banner.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Variables and Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to our lecture on **Random Variables and Probability Distributions**. This fundamental topic forms the backbone of probability theory and statistical analysis, playing a crucial role in machine learning and data science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we'll explore:\n",
    "\n",
    "- The concept of random variables and their types\n",
    "- How we describe the behavior of these variables using probability functions\n",
    "- Ways to summarize and analyze the characteristics of random variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is this important?**\n",
    "\n",
    "Random variables are our way of mathematically representing uncertain outcomes. Whether we're predicting stock prices, analyzing customer behavior, or modeling natural phenomena, random variables allow us to capture and work with uncertainty in a rigorous manner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider these real-world scenarios:\n",
    "\n",
    "1. A data scientist predicting the number of daily website visitors\n",
    "2. An epidemiologist modeling the spread of a disease\n",
    "3. A financial analyst estimating future currency exchange rates\n",
    "\n",
    "All of these involve random variables and their distributions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we dive deeper into machine learning, you'll find that many algorithms are built upon the foundation of probability distributions. For instance:\n",
    "\n",
    "- **Naive Bayes classifiers** use probability distributions to make predictions\n",
    "- **Gaussian Processes** rely heavily on the properties of normal distributions\n",
    "- **Maximum Likelihood Estimation**, a cornerstone of many ML techniques, is intimately tied to probability distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this lecture, you'll have a solid grasp of these concepts, enabling you to:\n",
    "\n",
    "1. Distinguish between discrete and continuous random variables\n",
    "2. Understand and interpret probability mass and density functions\n",
    "3. Work with cumulative distribution functions\n",
    "4. Calculate and interpret expected values, variances, and other moments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's embark on this probabilistic journey! ðŸŽ²ðŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Discrete and Continuous Random Variables](#toc1_)    \n",
    "  - [Discrete Random Variables](#toc1_1_)    \n",
    "  - [Continuous Random Variables](#toc1_2_)    \n",
    "  - [Examples and Comparisons](#toc1_3_)    \n",
    "- [Probability Mass Functions and Probability Density Functions](#toc2_)    \n",
    "  - [Probability Mass Functions (PMF)](#toc2_1_)    \n",
    "  - [Probability Density Functions (PDF)](#toc2_2_)    \n",
    "  - [Properties and Interpretations](#toc2_3_)    \n",
    "- [Cumulative Distribution Functions](#toc3_)    \n",
    "  - [Definition and Properties](#toc3_1_)    \n",
    "  - [Relationship with PMF and PDF](#toc3_2_)    \n",
    "  - [Applications of CDF](#toc3_3_)    \n",
    "- [Expectation, Variance, and Moments](#toc4_)    \n",
    "  - [Expected Value (Mean)](#toc4_1_)    \n",
    "  - [Variance and Standard Deviation](#toc4_2_)    \n",
    "  - [Higher-Order Moments](#toc4_3_)    \n",
    "  - [Practical Applications](#toc4_4_)    \n",
    "- [Summary and Key Takeaways](#toc5_)    \n",
    "- [Exercises](#toc6_)    \n",
    "  - [Exercise 1: Discrete Random Variable](#toc6_1_)    \n",
    "  - [Exercise 2: Continuous Random Variable](#toc6_2_)    \n",
    "  - [Exercise 3: Expected Value and Variance](#toc6_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Discrete and Continuous Random Variables](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random variables are fundamental to probability theory and statistics. They represent the possible outcomes of an experiment or random process. We categorize random variables into two main types: discrete and continuous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[Discrete Random Variables](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discrete random variables** can only take on a countable number of distinct values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key characteristics:**\n",
    "- The possible values can be listed out\n",
    "- There are gaps between potential values\n",
    "- Probabilities are assigned to each possible value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples:**\n",
    "1. Number of heads in 10 coin flips\n",
    "2. Count of defective items in a batch of 100\n",
    "3. Number of customers arriving at a store in an hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Placeholder for Discrete Random Variable Visualization]\n",
    "*Figure 1: Probability distribution of rolling a fair six-sided die*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[Continuous Random Variables](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous random variables** can take on any value within a given range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key characteristics:**\n",
    "- Values can be any real number within a range\n",
    "- No gaps between potential values\n",
    "- Probabilities are associated with ranges, not individual points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples:**\n",
    "1. Height of a person\n",
    "2. Time taken to complete a task\n",
    "3. Temperature at a specific location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Placeholder for Continuous Random Variable Visualization]\n",
    "*Figure 2: Probability density function of a standard normal distribution*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_'></a>[Examples and Comparisons](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the difference, let's consider two scenarios:\n",
    "\n",
    "1. **Discrete**: Number of eggs in a bird's nest\n",
    "   - Possible values: 0, 1, 2, 3, ...\n",
    "   - We can count exact numbers\n",
    "   - There's a probability associated with each specific number\n",
    "\n",
    "2. **Continuous**: Weight of an egg\n",
    "   - Possible values: Any real number > 0\n",
    "   - We measure to a certain precision (e.g., 50.237 grams)\n",
    "   - Probabilities are associated with ranges (e.g., probability of weight between 50g and 51g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Differences:**\n",
    "\n",
    "| Aspect | Discrete | Continuous |\n",
    "|--------|----------|------------|\n",
    "| Values | Countable set | Uncountable set |\n",
    "| Visualization | Bar graph or stem plot | Smooth curve |\n",
    "| Probability of exact value | Can be non-zero | Always zero |\n",
    "| Mathematical treatment | Sums | Integrals |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the nature of your random variable (discrete or continuous) is crucial in choosing the appropriate probability functions and analysis methods, which we'll explore in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[Probability Mass Functions and Probability Density Functions](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To describe the probability distribution of random variables, we use two fundamental concepts: Probability Mass Functions (PMF) for discrete random variables and Probability Density Functions (PDF) for continuous random variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_'></a>[Probability Mass Functions (PMF)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Probability Mass Function** (PMF) is used to describe the probability distribution of a discrete random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "For a discrete random variable $X$, the PMF $p_X(x)$ gives the probability that $X$ takes on the value $x$:\n",
    "\n",
    "$p_X(x) = P(X = x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties:**\n",
    "1. Non-negative: $p_X(x) \\geq 0$ for all $x$\n",
    "2. Sum to 1: $\\sum_x p_X(x) = 1$\n",
    "3. Probability of an event: $P(X \\in A) = \\sum_{x \\in A} p_X(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "Consider rolling a fair six-sided die. The PMF would be:\n",
    "\n",
    "$p_X(x) = \\begin{cases} \n",
    "\\frac{1}{6} & \\text{for } x = 1, 2, 3, 4, 5, 6 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Placeholder for PMF Visualization]\n",
    "*Figure 3: PMF of rolling a fair six-sided die*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_'></a>[Probability Density Functions (PDF)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Probability Density Function** (PDF) is used to describe the probability distribution of a continuous random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "For a continuous random variable $X$, the PDF $f_X(x)$ is a function such that the probability of $X$ falling in an interval $[a, b]$ is given by the integral of $f_X(x)$ over that interval:\n",
    "\n",
    "$P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties:**\n",
    "1. Non-negative: $f_X(x) \\geq 0$ for all $x$\n",
    "2. Total area is 1: $\\int_{-\\infty}^{\\infty} f_X(x) dx = 1$\n",
    "3. $P(X = x) = 0$ for any single point $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "The PDF of a standard normal distribution (mean 0, variance 1) is given by:\n",
    "\n",
    "$f_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Placeholder for PDF Visualization]\n",
    "*Figure 4: PDF of a standard normal distribution*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_'></a>[Properties and Interpretations](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpreting PMF vs PDF:**\n",
    "- PMF: The height of the function directly gives the probability for each value.\n",
    "- PDF: The area under the curve over an interval gives the probability for that interval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Differences:**\n",
    "\n",
    "| Aspect | PMF | PDF |\n",
    "|--------|-----|-----|\n",
    "| Applies to | Discrete RVs | Continuous RVs |\n",
    "| Range | [0, 1] | [0, âˆž) |\n",
    "| Sum/Integral | Sums to 1 | Integrates to 1 |\n",
    "| Interpretation | P(X = x) | Not directly interpretable |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes:**\n",
    "1. For a PDF, $f_X(x)$ itself is not a probability. It can be greater than 1.\n",
    "2. The units of a PDF are the reciprocal of the units of the random variable.\n",
    "3. While we can't interpret $f_X(x)$ directly as a probability, we can use it to compare the relative likelihood of different outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding PMFs and PDFs is crucial for calculating probabilities, making inferences, and applying various statistical techniques in data analysis and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[Cumulative Distribution Functions](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a fundamental concept in probability theory that applies to both discrete and continuous random variables. It provides a comprehensive description of the probability distribution of a random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_'></a>[Definition and Properties](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "For a random variable $X$, the Cumulative Distribution Function $F_X(x)$ is defined as:\n",
    "\n",
    "$F_X(x) = P(X \\leq x)$\n",
    "\n",
    "This function gives the probability that the random variable $X$ takes on a value less than or equal to $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties:**\n",
    "1. **Monotonically increasing**: If $a < b$, then $F_X(a) \\leq F_X(b)$\n",
    "2. **Right-continuous**: $\\lim_{x \\to a^+} F_X(x) = F_X(a)$\n",
    "3. **Limits**: \n",
    "   - $\\lim_{x \\to -\\infty} F_X(x) = 0$\n",
    "   - $\\lim_{x \\to \\infty} F_X(x) = 1$\n",
    "4. **Probability of an interval**: $P(a < X \\leq b) = F_X(b) - F_X(a)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Placeholder for CDF Visualization]\n",
    "*Figure 5: CDF of a standard normal distribution*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_'></a>[Relationship with PMF and PDF](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDF is closely related to both the Probability Mass Function (PMF) for discrete random variables and the Probability Density Function (PDF) for continuous random variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Discrete Random Variables:**\n",
    "- CDF is a step function\n",
    "- Relationship with PMF: $F_X(x) = \\sum_{t \\leq x} p_X(t)$\n",
    "- PMF can be derived from CDF: $p_X(x) = F_X(x) - F_X(x^-)$, where $x^-$ is the value just before $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Continuous Random Variables:**\n",
    "- CDF is a continuous function\n",
    "- Relationship with PDF: $F_X(x) = \\int_{-\\infty}^x f_X(t) dt$\n",
    "- PDF can be derived from CDF: $f_X(x) = \\frac{d}{dx}F_X(x)$ (when the derivative exists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_'></a>[Applications of CDF](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Calculating Probabilities**: \n",
    "   - $P(X \\leq a) = F_X(a)$\n",
    "   - $P(a < X \\leq b) = F_X(b) - F_X(a)$\n",
    "   - $P(X > a) = 1 - F_X(a)$\n",
    "\n",
    "2. **Quantile Calculation**: \n",
    "   The $p$-th quantile is the value $x_p$ such that $F_X(x_p) = p$. This is particularly useful for finding medians (50th percentile) and other percentiles.\n",
    "\n",
    "3. **Generating Random Numbers**: \n",
    "   The inverse transform sampling method uses the inverse of the CDF to generate random numbers from any probability distribution.\n",
    "\n",
    "4. **Stochastic Ordering**: \n",
    "   CDFs can be used to compare different distributions and establish stochastic dominance.\n",
    "\n",
    "5. **Survival Analysis**: \n",
    "   In reliability theory and survival analysis, the complement of the CDF (1 - CDF) is known as the survival function.\n",
    "\n",
    "6. **Kolmogorov-Smirnov Test**: \n",
    "   This statistical test uses the CDF to determine if a sample comes from a population with a specific distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Application:**\n",
    "Suppose we have a normally distributed random variable $X$ with mean $\\mu=10$ and standard deviation $\\sigma=2$. We can use the CDF to answer questions like:\n",
    "\n",
    "- What's the probability that $X$ is less than 12?\n",
    "- What value of $X$ is greater than 95% of all possible values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding CDFs is crucial in many areas of statistics and machine learning, including hypothesis testing, confidence interval estimation, and predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_'></a>[Expectation, Variance, and Moments](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moments are numerical measures that provide important information about the shape and characteristics of probability distributions. We'll explore the most commonly used moments: expected value (first moment), variance (second central moment), and briefly touch on higher-order moments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_'></a>[Expected Value (Mean)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **expected value**, also known as the mean, is a measure of central tendency for a random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "For a discrete random variable $X$ with PMF $p_X(x)$:\n",
    "- $E[X] = \\sum_x x \\cdot p_X(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a continuous random variable $X$ with PDF $f_X(x)$:\n",
    "- $E[X] = \\int_{-\\infty}^{\\infty} x \\cdot f_X(x) dx$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties:**\n",
    "1. Linearity: $E[aX + b] = aE[X] + b$\n",
    "2. For independent random variables: $E[XY] = E[X]E[Y]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** The expected value represents the long-run average of the random variable over many trials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_2_'></a>[Variance and Standard Deviation](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance** measures the spread or dispersion of a random variable around its mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "$Var(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables:\n",
    "$Var(X) = \\sum_x (x - E[X])^2 \\cdot p_X(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous random variables:\n",
    "$Var(X) = \\int_{-\\infty}^{\\infty} (x - E[X])^2 \\cdot f_X(x) dx$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Deviation** is the square root of the variance:\n",
    "$\\sigma_X = \\sqrt{Var(X)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties:**\n",
    "1. $Var(X) \\geq 0$\n",
    "2. $Var(aX + b) = a^2Var(X)$\n",
    "3. For independent random variables: $Var(X + Y) = Var(X) + Var(Y)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Variance and standard deviation quantify the average deviation from the mean, providing a measure of uncertainty or spread in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_3_'></a>[Higher-Order Moments](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher-order moments provide additional information about the shape of the distribution.\n",
    "\n",
    "1. **Third Central Moment (Skewness):**\n",
    "   $E[(X - E[X])^3]$\n",
    "   - Measures asymmetry of the distribution\n",
    "   - Positive skew: right tail is longer\n",
    "   - Negative skew: left tail is longer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Fourth Central Moment (Kurtosis):**\n",
    "   $E[(X - E[X])^4]$\n",
    "   - Measures the \"tailedness\" of the distribution\n",
    "   - Higher kurtosis indicates heavier tails and a higher, sharper peak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardized Moments:**\n",
    "To make moments comparable across different scales, we often use standardized moments:\n",
    "\n",
    "$\\text{Standardized Moment}_n = \\frac{E[(X - E[X])^n]}{\\sigma^n}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_4_'></a>[Practical Applications](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Summary:** Mean and variance provide a concise summary of a dataset's central tendency and spread.\n",
    "\n",
    "2. **Financial Risk Management:** Variance and higher moments are used to assess investment risk and portfolio optimization.\n",
    "\n",
    "3. **Quality Control:** In manufacturing, variance is used to measure process consistency and identify areas for improvement.\n",
    "\n",
    "4. **Machine Learning:**\n",
    "   - Feature scaling often involves normalizing data using mean and standard deviation.\n",
    "   - Many algorithms assume normally distributed data, which is characterized by its first two moments.\n",
    "\n",
    "5. **Hypothesis Testing:** Many statistical tests, like t-tests and ANOVA, rely on assumptions about population moments.\n",
    "\n",
    "6. **Signal Processing:** Moments are used in image analysis for feature extraction and pattern recognition.\n",
    "\n",
    "7. **Anomaly Detection:** Unusual data points can be identified by their deviation from expected moments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Application:**\n",
    "In a machine learning context, consider a dataset of house prices. The mean price gives us a central reference point, while the variance indicates the spread of prices. Skewness might reveal whether there are more high-end outliers (positive skew) or low-end outliers (negative skew). This information can guide feature engineering, help in identifying outliers, and inform the choice of model or preprocessing steps.\n",
    "\n",
    "Understanding these concepts is crucial for data scientists and machine learning practitioners, as they form the foundation for many advanced statistical techniques and machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_'></a>[Summary and Key Takeaways](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we've explored the fundamental concepts of random variables and probability distributions. Let's recap the main points and highlight their importance in the field of machine learning and data science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key concepts covered:\n",
    "1. **Random Variables**\n",
    "   - Discrete: Countable outcomes (e.g., number of customers)\n",
    "   - Continuous: Uncountable outcomes (e.g., temperature)\n",
    "\n",
    "2. **Probability Functions**\n",
    "   - Probability Mass Function (PMF) for discrete variables\n",
    "   - Probability Density Function (PDF) for continuous variables\n",
    "   - Cumulative Distribution Function (CDF) for both types\n",
    "\n",
    "3. **Moments**\n",
    "   - Expected Value (Mean): Measure of central tendency\n",
    "   - Variance and Standard Deviation: Measures of spread\n",
    "   - Higher-order moments: Skewness and Kurtosis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Important takeaways:\n",
    "1. **Choice of Distribution**: Understanding the nature of your data (discrete vs. continuous) is crucial in selecting the appropriate probability function and analysis methods.\n",
    "\n",
    "2. **Interpretability**: While PMFs directly give probabilities, PDFs require integration over intervals to yield probabilities.\n",
    "\n",
    "3. **CDF Versatility**: The Cumulative Distribution Function is applicable to both discrete and continuous variables, making it a powerful tool for probability calculations.\n",
    "\n",
    "4. **Moments and Data Characteristics**: Moments provide valuable insights into the shape and properties of distributions, guiding feature engineering and model selection in machine learning.\n",
    "\n",
    "5. **Practical Applications**: These concepts form the foundation for various machine learning techniques, including:\n",
    "   - Bayesian inference\n",
    "   - Maximum likelihood estimation\n",
    "   - Hypothesis testing\n",
    "   - Anomaly detection\n",
    "   - Risk assessment in financial models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why This Matters in Machine Learning?\n",
    "1. **Data Understanding**: Proper characterization of your data's distribution is essential for effective preprocessing and feature engineering.\n",
    "\n",
    "2. **Model Assumptions**: Many machine learning algorithms make assumptions about the underlying data distribution (e.g., Gaussian Naive Bayes assumes normal distribution).\n",
    "\n",
    "3. **Probabilistic Models**: Techniques like Gaussian Mixture Models and Hidden Markov Models directly leverage these probability concepts.\n",
    "\n",
    "4. **Uncertainty Quantification**: Understanding probability distributions allows for better estimation of prediction uncertainties in models.\n",
    "\n",
    "5. **Sampling and Simulation**: Generating synthetic data or performing bootstrap sampling relies on a solid grasp of probability distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you progress in your machine learning journey, you'll find these concepts recurring in various contexts. Whether you're working with neural networks, decision trees, or reinforcement learning algorithms, a strong foundation in probability theory will enhance your ability to understand, implement, and innovate in the field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, mastering these concepts takes practice. In the exercises that follow, you'll have the opportunity to apply these ideas to concrete problems, further solidifying your understanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By internalizing these fundamental principles of random variables and probability distributions, you're equipping yourself with a powerful toolkit for tackling complex machine learning challenges. Keep exploring, and don't hesitate to revisit these concepts as you encounter them in more advanced topics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_'></a>[Exercises](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your understanding of random variables and probability distributions with these exercises. Try to solve them on your own before checking the solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc6_1_'></a>[Exercise 1: Discrete Random Variable](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fair six-sided die is rolled twice. Let X be the random variable representing the sum of the two rolls.\n",
    "\n",
    "a) Is X a discrete or continuous random variable?\n",
    "b) What are the possible values of X?\n",
    "c) Calculate the probability mass function (PMF) for X.\n",
    "d) What is P(X > 8)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) X is a discrete random variable.\n",
    "\n",
    "b) The possible values of X are 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12.\n",
    "\n",
    "c) PMF:\n",
    "- P(X = 2) = 1/36\n",
    "- P(X = 3) = 2/36\n",
    "- P(X = 4) = 3/36\n",
    "- P(X = 5) = 4/36\n",
    "- P(X = 6) = 5/36\n",
    "- P(X = 7) = 6/36\n",
    "- P(X = 8) = 5/36\n",
    "- P(X = 9) = 4/36\n",
    "- P(X = 10) = 3/36\n",
    "- P(X = 11) = 2/36\n",
    "- P(X = 12) = 1/36\n",
    "\n",
    "d) P(X > 8) = P(X = 9) + P(X = 10) + P(X = 11) + P(X = 12)\n",
    "             = 4/36 + 3/36 + 2/36 + 1/36 = 10/36 = 5/18 â‰ˆ 0.2778\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc6_2_'></a>[Exercise 2: Continuous Random Variable](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the time (in minutes) a customer spends in a store follows a normal distribution with mean Î¼ = 30 and standard deviation Ïƒ = 5.\n",
    "\n",
    "a) What is the probability that a randomly selected customer spends between 25 and 35 minutes in the store?\n",
    "b) What is the probability that a customer spends more than 40 minutes in the store?\n",
    "c) What time duration covers the middle 95% of customers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let X be the time spent in the store. X ~ N(30, 5Â²)\n",
    "\n",
    "a) P(25 < X < 35) = P((25-30)/5 < Z < (35-30)/5) = P(-1 < Z < 1)\n",
    "                  = 0.8413 - 0.1587 = 0.6826\n",
    "\n",
    "b) P(X > 40) = P(Z > (40-30)/5) = P(Z > 2) = 1 - 0.9772 = 0.0228\n",
    "\n",
    "c) For the middle 95%, we need the 2.5th and 97.5th percentiles.\n",
    "   These correspond to Z-scores of -1.96 and 1.96.\n",
    "\n",
    "- Lower bound: 30 + (-1.96 * 5) = 20.2 minutes\n",
    "- Upper bound: 30 + (1.96 * 5) = 39.8 minutes\n",
    "\n",
    "The middle 95% of customers spend between 20.2 and 39.8 minutes in the store.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc6_3_'></a>[Exercise 3: Expected Value and Variance](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A game involves rolling a fair six-sided die. If the number is even, you win that amount in dollars. If it's odd, you lose that amount in dollars.\n",
    "\n",
    "a) Define the random variable X for this game.\n",
    "b) Calculate the expected value E[X].\n",
    "c) Calculate the variance Var(X).\n",
    "d) Is this game fair? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "a) X = {\n",
    "     -1 with probability 1/6\n",
    "     -3 with probability 1/6\n",
    "     -5 with probability 1/6\n",
    "     2 with probability 1/6\n",
    "     4 with probability 1/6\n",
    "     6 with probability 1/6\n",
    "   }\n",
    "\n",
    "b) E[X] = (-1 * 1/6) + (-3 * 1/6) + (-5 * 1/6) + (2 * 1/6) + (4 * 1/6) + (6 * 1/6)\n",
    "        = (-9 + 12) / 6 = 3/6 = 0.5\n",
    "\n",
    "c) E[XÂ²] = (1Â² * 1/6) + (3Â² * 1/6) + (5Â² * 1/6) + (2Â² * 1/6) + (4Â² * 1/6) + (6Â² * 1/6)\n",
    "         = (1 + 9 + 25 + 4 + 16 + 36) / 6 = 91/6 = 15.1667\n",
    "\n",
    "- Var(X) = E[XÂ²] - (E[X])Â² = 15.1667 - 0.5Â² = 14.9167\n",
    "\n",
    "d) The game is not fair because E[X] â‰  0. On average, the player wins $0.50 per game, making it favorable to the player.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These exercises cover key concepts from the lecture, including working with discrete and continuous random variables, calculating probabilities using PMFs and PDFs, and computing expected values and variances. They also demonstrate practical applications of these concepts in real-world scenarios."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
